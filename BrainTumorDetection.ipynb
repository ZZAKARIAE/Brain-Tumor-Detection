{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cd20cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zzaka\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Importation des bibliothèques necessaires\n",
    "# CV2 de OpenCV pour la lecture et le traitement d'image\n",
    "import cv2\n",
    "# Os pour importer la base de données\n",
    "import os\n",
    "# Numpy pour le calcule matricielle et matplotlib.pyplot pour la dataviz\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Tensorflow et keras pour construire le réseau de neurones \n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27877201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour automatiser le traitement d'image\n",
    "def traitement_img (img) : \n",
    "    if img is not None:\n",
    "    # Changement des couleurs en nuances de gris\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Changement de la taille de l'image \n",
    "        img = cv2.resize(img, (128, 128))\n",
    "    # Normalisation des pixels de l'image (division sur 255)\n",
    "        img = img / 255\n",
    "    return img\n",
    "    print (f\"échec de traitement de le l'image {img}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d16c54",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: 'C:/Users/zzaka/OneDrive/Bureau/notumor_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m path_no_tumor_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/zzaka/OneDrive/Bureau/notumor_train\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m path_tumor_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/zzaka/OneDrive/Bureau/tumor_train\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m no_tumor_images_train \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(path_no_tumor_train)\n\u001b[0;32m      5\u001b[0m tumor_images_train \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(path_tumor_train)\n\u001b[0;32m      7\u001b[0m training_dataset \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: 'C:/Users/zzaka/OneDrive/Bureau/notumor_train'"
     ]
    }
   ],
   "source": [
    "path_no_tumor_train = \"C:/Users/zzaka/OneDrive/Bureau/notumor_train\"\n",
    "path_tumor_train = \"C:/Users/zzaka/OneDrive/Bureau/tumor_train\"\n",
    "\n",
    "no_tumor_images_train = os.listdir(path_no_tumor_train)\n",
    "tumor_images_train = os.listdir(path_tumor_train)\n",
    "\n",
    "training_dataset = []\n",
    "training_label = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "188c6fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image chargée avec succès!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image_path = \"C:/Users/zzaka/OneDrive/Bureau/tumor_train/Tr-gl_0012.jpg\"\n",
    "\n",
    "# Tenter de charger l'image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Vérifier si l'image a été chargée correctement\n",
    "if image is not None:\n",
    "    print(\"Image chargée avec succès!\")\n",
    "    # Voir l'image chargée\n",
    "    cv2.imshow('Image', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(f\"Échec du chargement de l'image à partir de {image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23f9e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle pour les images sans tumeur\n",
    "for image_name in no_tumor_images_train:\n",
    "    full_path = os.path.join(path_no_tumor_train, image_name)  # Construction du chemin complet\n",
    "\n",
    "    # Charger l'image\n",
    "    image = cv2.imread(full_path)\n",
    "    \n",
    "    # Vérifier si l'image a été chargée correctement\n",
    "    if image is None:\n",
    "        print(f\"Impossible de charger l'image {full_path}.\")\n",
    "        continue\n",
    "\n",
    "    # Conversion en niveaux de gris et redimensionnement\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    img = img / 255.0  # Normalisation des valeurs des pixels\n",
    "\n",
    "    # Ajouter l'image et l'étiquette à leurs listes respectives\n",
    "    training_dataset.append(img)\n",
    "    training_label.append(0)  # 0 pour 'sans tumeur'\n",
    "\n",
    "# Boucle pour les images avec tumeur\n",
    "for image_name in tumor_images_train:\n",
    "    full_path = os.path.join(path_tumor_train, image_name)  # Construction du chemin complet\n",
    "\n",
    "    # Charger l'image\n",
    "    image = cv2.imread(full_path)\n",
    "    \n",
    "    # Vérifier si l'image a été chargée correctement\n",
    "    if image is None:\n",
    "        print(f\"Impossible de charger l'image {full_path}.\")\n",
    "        continue\n",
    "\n",
    "    # Conversion en niveaux de gris et redimensionnement\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    img = img / 255.0  # Normalisation des valeurs des pixels\n",
    "\n",
    "    # Ajouter l'image et l'étiquette à leurs listes respectives\n",
    "    training_dataset.append(img)\n",
    "    training_label.append(1)  # 1 pour 'avec tumeur'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter le nombre d'occurrences de chaque classe\n",
    "counts = [training_label.count(0), training_label.count(1)]\n",
    "\n",
    "# Définir les étiquettes pour les classes\n",
    "labels = ['No_tumor', 'Tumor']\n",
    "\n",
    "# Créer un diagramme \n",
    "plt.pie(counts, labels=labels, autopct='%1.1f%%', colors=['blue', 'orange'], startangle=90)\n",
    "\n",
    "# Ajouter le titres \n",
    "plt.title('Répartition des classes')\n",
    "\n",
    "# Afficher le diagramme\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e69f1afc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Transformer les images en matrice de pixel avec numpy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m training_dataset \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(training_dataset)\n\u001b[0;32m      3\u001b[0m training_label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(training_label)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# On mélange les listes des labels et des matrices d'images\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Transformer les images en matrice de pixel avec numpy\n",
    "training_dataset = np.array(training_dataset)\n",
    "training_label = np.array(training_label)\n",
    "\n",
    "# On mélange les listes des labels et des matrices d'images\n",
    "training_dataset, label = shuffle(training_dataset,training_label)\n",
    "\n",
    "print(\"taille du dataset : \", len(training_dataset))\n",
    "print(\"shape du dataset : \", training_dataset.shape)\n",
    "\n",
    "print(\"taille des label : \", len(training_label))\n",
    "print(\"shape du label : \", training_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f7cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser la base de données en ensemble de test et d'entrainement\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(training_dataset, training_label,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "024d8528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "int32\n",
      "False\n",
      "False\n",
      "(4284, 128, 128)\n",
      "(4284,)\n"
     ]
    }
   ],
   "source": [
    "# Vérifier le types des variables X et Y\n",
    "print(X_train.dtype)\n",
    "print(y_train.dtype)\n",
    "\n",
    "# Vérifier qu'aucune liste n'a de valeur nulle\n",
    "print(np.any(np.isnan(X_train)))\n",
    "print(np.any(np.isnan(y_train)))\n",
    "\n",
    "# Vérifier le shape de X et Y pour programmer l'entrée et la sortie du modèle\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d139af74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "739d7380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "134/134 [==============================] - 73s 526ms/step - loss: 0.5980 - accuracy: 0.7213\n",
      "Epoch 2/5\n",
      "134/134 [==============================] - 73s 546ms/step - loss: 0.5965 - accuracy: 0.7218\n",
      "Epoch 3/5\n",
      "134/134 [==============================] - 71s 527ms/step - loss: 0.5948 - accuracy: 0.7218\n",
      "Epoch 4/5\n",
      "134/134 [==============================] - 71s 530ms/step - loss: 0.5930 - accuracy: 0.7218\n",
      "Epoch 5/5\n",
      "134/134 [==============================] - 71s 533ms/step - loss: 0.5939 - accuracy: 0.7218\n",
      "45/45 [==============================] - 5s 101ms/step - loss: 0.5954 - accuracy: 0.7178\n",
      "Accuracy :  0.7177870869636536\n",
      "Loss :  0.5954132080078125\n",
      "45/45 [==============================] - 5s 108ms/step\n",
      "Nombre de faux négatives :  0\n"
     ]
    }
   ],
   "source": [
    "# Initialiser des listes vides pour stocker les résultats de l'entrainement des modèles ainsi que les modèles entrainés\n",
    "#liste_faux_negatifs = []\n",
    "#accuracies = []\n",
    "#modeles = []\n",
    "\n",
    "# Initialiser une liste contenant les nombres de kernel que l'on souhaite tester\n",
    "#taille_kernel = [16, 32, 64]\n",
    "\n",
    "# Bdeux boucles pour tester toutes les combianisons possible entre le nombre de kernel et la taille des kernels\n",
    "#for i in range (1, 7):\n",
    "#    for e in taille_kernel :\n",
    "\n",
    "# Initialiser un modèle séquentielle qu'on va compiler par la suite (pour rajouter les couche manuellement)\n",
    "model = Sequential()\n",
    "\n",
    "# Couche d'entrée : convolution (le modèle reçoit des images dont la matrice est  de taille 128 par 128 \n",
    "model.add(Conv2D(64, (3, 3), input_shape=(128, 128, 1), padding='same',kernel_initializer='uniform',activation='relu'))\n",
    "\n",
    "# Couches cachées :\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same',kernel_initializer='uniform',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same',kernel_initializer='uniform',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same',kernel_initializer='uniform',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(64,activation='relu'))\n",
    "\n",
    "# Couche de sortie\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "# Compilation des couches du modèles\n",
    "model.compile(loss='binary_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
    "\n",
    "# Entrainement du modèle\n",
    "history = model.fit(X_train, y_train, epochs=5)\n",
    "        #modeles.append(model)\n",
    "\n",
    "# Evaluation sur la base de test\n",
    "loss, accuracy = model.evaluate(X_test_val, y_test_val)\n",
    "        #accuracies.append(accuracy)\n",
    "print(\"Accuracy : \", accuracy)\n",
    "print(\"Loss : \", loss)\n",
    "\n",
    "        # Prédiction sur l'ensemble de test\n",
    "y_pred = model.predict(X_test_val)\n",
    "y_pred_classes = (y_pred > 0.5).astype(\"int32\")\n",
    "\n",
    "        # Création de la matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test_val, y_pred_classes)\n",
    "\n",
    "        # Extraction des faux négatifs et ajout à la liste\n",
    "faux_negatifs = conf_matrix[1, 0]\n",
    "        #liste_faux_negatifs.append(faux_negatifs)\n",
    "print(\"Nombre de faux négatives : \", faux_negatifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "193ce424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement du modèle avec la bibliothèque keras\n",
    "model.save(\"C:/Users/zzaka/OneDrive/Bureau/modele_opti_deuxclasses.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
